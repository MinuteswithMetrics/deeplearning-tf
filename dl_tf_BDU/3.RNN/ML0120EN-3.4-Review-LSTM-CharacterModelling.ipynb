{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Big Data University](https://ibm.box.com/shared/static/jvcqp2iy2jlx2b32rmzdt0tx8lvxgzkp.png)\n",
    "# <center> Text generation using RNN/LSTM (Character-level)</center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<font size = 3><strong>In this notebook you will learn the How to use TensorFlow for create a Recurrent Neural Network</strong></font>\n",
    "<br>    \n",
    "- <a href=\"#intro\">Introduction</a>\n",
    "<br>\n",
    "- <p><a href=\"#arch\">Architectures</a></p>\n",
    "    - <a href=\"#lstm\">Long Short-Term Memory Model (LSTM)</a>\n",
    "\n",
    "- <p><a href=\"#build\">Building a LSTM with TensorFlow</a></p>\n",
    "</div>\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code implements a Recurrent Neural Network with LSTM/RNN units for training/sampling from character-level language models. In other words the model takes a text file as input and trains the RNN network that learns to predict the next character in a sequence.  \n",
    "The RNN can then be used to generate text character by character that will look like the original training data. \n",
    "\n",
    "This code is based on this [blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), and the code is an step-by-step implimentation of the [character-level implimentation](https://github.com/crazydonkey200/tensorflow-char-rnn).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.1.0\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader\n",
    "The following cell is a class that help to read data from input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import collections\n",
    "from six.moves import cPickle\n",
    "import numpy as np\n",
    "\n",
    "class TextLoader():\n",
    "    def __init__(self, data_dir, batch_size, seq_length, encoding='utf-8'):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_length = seq_length\n",
    "        self.encoding = encoding\n",
    "\n",
    "        input_file = os.path.join(data_dir, \"input.txt\")\n",
    "        vocab_file = os.path.join(data_dir, \"vocab.pkl\")\n",
    "        tensor_file = os.path.join(data_dir, \"data.npy\")\n",
    "\n",
    "        if not (os.path.exists(vocab_file) and os.path.exists(tensor_file)):\n",
    "            print(\"reading text file\")\n",
    "            self.preprocess(input_file, vocab_file, tensor_file)\n",
    "        else:\n",
    "            print(\"loading preprocessed files\")\n",
    "            self.load_preprocessed(vocab_file, tensor_file)\n",
    "        self.create_batches()\n",
    "        self.reset_batch_pointer()\n",
    "\n",
    "    def preprocess(self, input_file, vocab_file, tensor_file):\n",
    "        with codecs.open(input_file, \"r\", encoding=self.encoding) as f:\n",
    "            data = f.read()\n",
    "        counter = collections.Counter(data)\n",
    "        count_pairs = sorted(counter.items(), key=lambda x: -x[1])\n",
    "        self.chars, _ = zip(*count_pairs)\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.vocab = dict(zip(self.chars, range(len(self.chars))))\n",
    "        with open(vocab_file, 'wb') as f:\n",
    "            cPickle.dump(self.chars, f)\n",
    "        self.tensor = np.array(list(map(self.vocab.get, data)))\n",
    "        np.save(tensor_file, self.tensor)\n",
    "\n",
    "    def load_preprocessed(self, vocab_file, tensor_file):\n",
    "        with open(vocab_file, 'rb') as f:\n",
    "            self.chars = cPickle.load(f)\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.vocab = dict(zip(self.chars, range(len(self.chars))))\n",
    "        self.tensor = np.load(tensor_file)\n",
    "        self.num_batches = int(self.tensor.size / (self.batch_size *\n",
    "                                                   self.seq_length))\n",
    "\n",
    "    def create_batches(self):\n",
    "        self.num_batches = int(self.tensor.size / (self.batch_size *\n",
    "                                                   self.seq_length))\n",
    "\n",
    "        # When the data (tensor) is too small, let's give them a better error message\n",
    "        if self.num_batches==0:\n",
    "            assert False, \"Not enough data. Make seq_length and batch_size small.\"\n",
    "\n",
    "        self.tensor = self.tensor[:self.num_batches * self.batch_size * self.seq_length]\n",
    "        xdata = self.tensor\n",
    "        ydata = np.copy(self.tensor)\n",
    "        ydata[:-1] = xdata[1:]\n",
    "        ydata[-1] = xdata[0]\n",
    "        self.x_batches = np.split(xdata.reshape(self.batch_size, -1), self.num_batches, 1)\n",
    "        self.y_batches = np.split(ydata.reshape(self.batch_size, -1), self.num_batches, 1)\n",
    "\n",
    "\n",
    "    def next_batch(self):\n",
    "        x, y = self.x_batches[self.pointer], self.y_batches[self.pointer]\n",
    "        self.pointer += 1\n",
    "        return x, y\n",
    "\n",
    "    def reset_batch_pointer(self):\n",
    "        self.pointer = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "#### Batch, number_of_batch, batch_size and seq_length\n",
    "what is batch, number_of_batch, batch_size and seq_length in the charcter level example?  \n",
    "\n",
    "Lets assume the input is 'here is an example'. Then:\n",
    "- txt_length = 18  \n",
    "- seq_length = 3  \n",
    "- batch_size = 2  \n",
    "- number_of_batch = 18/3*2 = 3\n",
    "- batch = array (['h','e','r'],['e',' ','i'])\n",
    "- sample Seq = 'her'  \n",
    "\n",
    "\n",
    "So, what are our actual parameters?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 60 #minibatch size, i.e. size of dataset in each epoch\n",
    "seq_length = 50 #RNN sequence length\n",
    "num_epochs = 25 # you should change it to 50 if you want to see a relatively good results\n",
    "learning_rate = 0.002\n",
    "decay_rate = 0.97\n",
    "rnn_size = 128 #size of RNN hidden state\n",
    "num_layers = 2 #number of layers in the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Architecture\n",
    "- each LSTM cell has an input layre, which its size is 128 units. \n",
    "- 128 is dimensionality of embedding vector.\n",
    "\n",
    "\n",
    "\n",
    "#### rnn_size = num_units = num_hidden_units:   = LSTM size\n",
    "\n",
    "\n",
    "- Each LSTM cell has a hidden layer, where there are some hidden units.\n",
    "- The argument n_hidden=128 of BasicLSTMCell is the number of hidden units of the LSTM (inside A).\n",
    "- Each LSTM cell keeps a vector, called __hidden state__ vector, of size n_hidden=128.\n",
    "- A __hidden state__ vector; which is the memory of the LSTM, accumulates using its (forget, input, and output) gates through time. \n",
    "- For each LSTM cell that we initialise, we need to supply a value (128 in this case) for the hidden dimension, or as some people like to call it, the number of units in the LSTM cell. \n",
    "- \"num_units\" is equivalant to \"size of RNN hidden state\"\n",
    "- rnn_size= 128, is also the dimension size of W2V/embedding, for each character/word.\n",
    "- An LSTM keeps two pieces of information as it propagates through time: \n",
    "    - A __hidden state__ vector\n",
    "    - A __previous time-step output__\n",
    "- To make the name num_units more intuitive, you can think of it as the number of hidden units in the LSTM cell, or the number of memory units in the cell.\n",
    "- number of hidden units is the dimensianality of the output (= dimesianality of the state) of the LSTM cell.\n",
    "\n",
    "#### num_layers = 2 \n",
    "- number of layers in the RNN\n",
    "- An input of MultiRNNCell is __cells__ which is list of RNNCells that will be composed in this order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-23 10:49:23 URL:https://public.boxcloud.com/d/1/GlcYgZJR3rfWY5w4a_kuVUXqKbHq-E2WEdL4t5SaMzl9ynLKF8O179kzBkAWcQ_3bftp36Kku38Bsg3Mh5G5qkYgWV_DeKR7i-3GtDjfyXCQeTLCH5zDlsE-TsQBnYv2g0H45sVs1U13T4ny2gIaXERiwdUTbHZe1XG7wsWOTklWW8v6vS8ZWjfpaLx9-CfKPcIJLs1MqCs6G07vla_6xwh5ijAH8POcgKkqUtMqqvQLLv8jWMYbZmz951uZYhPynbgJ4MD8YcMdG50fF7gi8rlLpxUSOuYG5ai47wKoAvU14SQ2k6fDmMikIg5N0uSgwBSTYQx-onBzYVmeWM-1DO97u5X4oI_XfEJbC3frtD8x7QVZYswqSTDHkCG6FTugVaOkBeLDr33WtYCBJ3mGydelHueaZaG1v5H14YyK5Xc_cn0vV0bsNa2fGZKQzwVVMD71nGr4ZosQBNzrDldQkvmvH7mik2knOl3LFkFnnpBPzCMbdP8oWe5h1y3miR6myY6txDNF0rga-8OXabMKeETvxNkk9w0ALnHo7D8nYp4_IjUHXIIvQzOHG41piyKOUD26drbNjrj5vMG0Ij3OvYJxDE9e_LeqmfdURW76obvuLIiaA6Ju1Kx5rTkPz_YuIem3r1oRqr6syB0qePMd0ecuPqbku9b3bmmVkt2ZGPuIoOQ7Bk7Ein7K-N6qPlLhAX4eU4qzg-07qhJZKRCulKbXBbRv5-XbinDYU8K3OFyzcQXVBnvwdZ4EEecsCgHPsq1TH1NpjdLkNiIBkyEgD4oqbDoc64FbciDW6qtN-uAfkcZBd4N8bDCrvVV3IWv3V-INVPoXFEWjFLvzmi6hq3w-4OZXHvYfoXPV_u7f0XaspqQHIE2TdK6fiBZqWK2FADSf9K2C-PEB-VEUdYH6w6egin1VX3fj544ftQ8mwUxzH1rzdG3fbpA2d6JKRB-Mur-f1je-v1KtvdvoaXD-2A6r9rHDK0ByI6PC17CG3fpyZeQkCFYUnB0Ue4am7k_9LaHH3FB16gO8hVHdoft_uvOolP2GBf35YHrLvdePPcJ4INcurdY-bTwVxSET2ZCyCapHKn1HVby5xtjtgLBtTzBZXg9xwtj4PBkFnClXyueNdwwkdp_qXU01Zl-OFVnvGt8thC3vFpBknrL6mgXaV1ou/download [1115393/1115393] -> \"../../data/character_model/input.txt\" [1]\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ../../data/character_model\n",
    "!wget -nv -O ../../data/character_model/input.txt https://ibm.box.com/shared/static/a3f9e9mbpup09toq35ut7ke3l3lf03hg.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading preprocessed files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = TextLoader('../../data/character_model/', batch_size, seq_length)\n",
    "vocab_size = data_loader.vocab_size\n",
    "data_loader.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = data_loader.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  9,  7, ...,  1,  4,  7],\n",
       "       [19,  4, 14, ..., 14,  9, 20],\n",
       "       [ 8, 20, 10, ...,  8, 10, 18],\n",
       "       ..., \n",
       "       [21,  2,  0, ...,  0, 21,  0],\n",
       "       [ 9,  7,  7, ...,  0,  2,  3],\n",
       "       [ 3,  7,  0, ...,  5,  9, 23]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape  #batch_size=60, seq_length=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  7,  6, ...,  4,  7,  0],\n",
       "       [ 4, 14, 22, ...,  9, 20,  5],\n",
       "       [20, 10, 29, ..., 10, 18,  4],\n",
       "       ..., \n",
       "       [ 2,  0,  6, ..., 21,  0,  6],\n",
       "       [ 7,  7,  4, ...,  2,  3,  0],\n",
       "       [ 7,  0, 33, ...,  9, 23,  0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 65\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary size:', data_loader.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ",  , !, $, &, ', ,, -, ., 3, :, ;, ?, A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(sorted(list(data_loader.chars))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.vocab['t']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining stacked RNN Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__BasicRNNCell__ is the most basic RNN cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a two layer cell\n",
    "with tf.variable_scope('multi_rnn_cell'):\n",
    "    stacked_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicRNNCell(rnn_size) for _ in range(num_layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden state size\n",
    "stacked_cell.output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_cell.state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = tf.placeholder(tf.int32, [batch_size, seq_length])# a 60x50\n",
    "targets = tf.placeholder(tf.int32, [batch_size, seq_length]) # a 60x50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory state of the network is initialized with a vector of zeros and gets updated after reading each character.\n",
    "\n",
    "__BasicRNNCell.zero_state(batch_size, dtype)__ Return zero-filled state tensor(s).\n",
    "\n",
    "Args:\n",
    "\n",
    "batch_size: int, float, or unit Tensor representing the batch size.  \n",
    "dtype: the data type to use for the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_state = stacked_cell.zero_state(batch_size, tf.float32) #why batch_size ? 60x128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(60, 50) dtype=int32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_dict={input_data:x, targets:y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  9,  7, ...,  1,  4,  7],\n",
       "       [19,  4, 14, ..., 14,  9, 20],\n",
       "       [ 8, 20, 10, ...,  8, 10, 18],\n",
       "       ..., \n",
       "       [21,  2,  0, ...,  0, 21,  0],\n",
       "       [ 9,  7,  7, ...,  0,  2,  3],\n",
       "       [ 3,  7,  0, ...,  5,  9, 23]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(input_data, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('rnnlm',reuse=False):\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size]) #128x65\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [vocab_size]) # 1x65)\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size])  #65x128\n",
    "        #input_data is a matrix of 60x50 and embedding is dictionary of 65x128 for all 65 characters\n",
    "        # embedding_lookup goes to each row of input_data, and for each character in the row, finds the correspond vector in embedding\n",
    "        # it creates a 60*50*[1*128] matrix\n",
    "        # so, the first elemnt of em, is a matrix of 50x128, which each row of it is vector representing that character\n",
    "        em = tf.nn.embedding_lookup(embedding, input_data) # em is 60x50x[1*128]\n",
    "        # split: Splits a tensor into sub tensors.\n",
    "        # syntax:  tf.split(split_dim, num_split, value, name='split')\n",
    "        # it will split the 60x50x[1x128] matrix into 50 matrix of 60x[1*128]\n",
    "        inputs = tf.split(em, seq_length, 1)\n",
    "        # It will convert the list to 50 matrix of [60x128]\n",
    "        inputs = [tf.squeeze(input_, [1]) for input_ in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00455077, -0.08505657,  0.00968477, ..., -0.11256096,\n",
       "         0.08936651,  0.13564713],\n",
       "       [-0.01204589,  0.01478565,  0.12983467, ...,  0.03713098,\n",
       "         0.07412069,  0.12602584],\n",
       "       [-0.00811039, -0.09547275, -0.00303565, ...,  0.1208431 ,\n",
       "        -0.02103838, -0.10411192],\n",
       "       ..., \n",
       "       [ 0.0258662 , -0.02935547, -0.1106279 , ...,  0.07244253,\n",
       "        -0.05265456, -0.07809801],\n",
       "       [-0.0670867 ,  0.08318488, -0.14293635, ..., -0.05563153,\n",
       "        -0.13975491,  0.12000434],\n",
       "       [-0.02657422, -0.14235181,  0.06278005, ...,  0.15116782,\n",
       "        -0.14109144,  0.17275174]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "session.run(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(60, 50, 128) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = tf.nn.embedding_lookup(embedding, input_data)\n",
    "em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 50, 128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp = session.run(em,feed_dict={input_data:x})\n",
    "emp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15181227,  0.01090705,  0.03806114, ..., -0.10365069,\n",
       "        -0.00031906,  0.00073797],\n",
       "       [ 0.05349265,  0.15286236,  0.16492094, ..., -0.14390934,\n",
       "        -0.05998485, -0.07160587],\n",
       "       [ 0.08706288,  0.11176957, -0.13602386, ...,  0.13116427,\n",
       "        -0.00431666, -0.07653115],\n",
       "       ..., \n",
       "       [-0.01204589,  0.01478565,  0.12983467, ...,  0.03713098,\n",
       "         0.07412069,  0.12602584],\n",
       "       [ 0.02244808,  0.09415562,  0.16566236, ...,  0.13478656,\n",
       "        -0.13616687, -0.02090606],\n",
       "       [ 0.08706288,  0.11176957, -0.13602386, ...,  0.13116427,\n",
       "        -0.00431666, -0.07653115]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'split:0' shape=(60, 1, 128) dtype=float32>,\n",
       " <tf.Tensor 'split:1' shape=(60, 1, 128) dtype=float32>,\n",
       " <tf.Tensor 'split:2' shape=(60, 1, 128) dtype=float32>,\n",
       " <tf.Tensor 'split:3' shape=(60, 1, 128) dtype=float32>,\n",
       " <tf.Tensor 'split:4' shape=(60, 1, 128) dtype=float32>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.split(em, seq_length, 1)\n",
    "inputs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Squeeze:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'Squeeze_1:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'Squeeze_2:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'Squeeze_3:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'Squeeze_4:0' shape=(60, 128) dtype=float32>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "inputs[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding a batch of 50 sequence to a RNN:\n",
    "- Step 1:  first character of each of the 50 sentences (in a batch) is input in parallel.  \n",
    "- Step 2:  second character of each of the 50 sentences is input in parallel. \n",
    "- Step n: nth character of each of the 50 sentences is input in parallel.  \n",
    "\n",
    "The parallelism is only for efficiency.  Each character in a batch is handled in parallel,  but the network sees one character of a sequence at a time and does the computations accordingly. All the computations involving the characters of all sequences in a batch at a given time step are done in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15181227,  0.01090705,  0.03806114, ..., -0.10365069,\n",
       "        -0.00031906,  0.00073797],\n",
       "       [ 0.11181198,  0.05652621, -0.14609113, ...,  0.07103869,\n",
       "        -0.01516595,  0.03015241],\n",
       "       [-0.04029936, -0.15443259, -0.05244369, ...,  0.15671606,\n",
       "         0.11565743,  0.04243562],\n",
       "       ..., \n",
       "       [ 0.13116498, -0.14643349, -0.15287329, ..., -0.10149479,\n",
       "        -0.10107021, -0.14191243],\n",
       "       [ 0.05349265,  0.15286236,  0.16492094, ..., -0.14390934,\n",
       "        -0.05998485, -0.07160587],\n",
       "       [ 0.11297508, -0.08271112, -0.14546309, ...,  0.09985153,\n",
       "        -0.06714724, -0.09677995]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(inputs[0],feed_dict={input_data:x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_cell.state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#outputs is 50x[60*128]\n",
    "outputs, last_state = tf.contrib.legacy_seq2seq.rnn_decoder(inputs, initial_state, stacked_cell, loop_function=None, scope='rnnlm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'rnnlm_1/multi_rnn_cell/cell_1/basic_rnn_cell/Tanh:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/multi_rnn_cell_1/cell_1/basic_rnn_cell/Tanh:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/multi_rnn_cell_2/cell_1/basic_rnn_cell/Tanh:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/multi_rnn_cell_3/cell_1/basic_rnn_cell/Tanh:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/multi_rnn_cell_4/cell_1/basic_rnn_cell/Tanh:0' shape=(60, 128) dtype=float32>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnnlm_1/multi_rnn_cell/cell_1/basic_rnn_cell/Tanh:0' shape=(60, 128) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = outputs[0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02281052, -0.10542833, -0.10928056, ...,  0.07889619,\n",
       "         0.02886342, -0.02457379],\n",
       "       [ 0.04373915,  0.01981135, -0.0588582 , ..., -0.05789723,\n",
       "        -0.04222565,  0.18353246],\n",
       "       [ 0.06870209,  0.11363489,  0.00273446, ...,  0.14812966,\n",
       "         0.00024029, -0.00936932],\n",
       "       ..., \n",
       "       [-0.03944357, -0.06743636, -0.04955675, ..., -0.01302843,\n",
       "         0.03449786, -0.04922117],\n",
       "       [-0.22960794, -0.10016541, -0.10149722, ...,  0.08571617,\n",
       "         0.06665474, -0.14481398],\n",
       "       [ 0.01329976,  0.09442141, -0.06003638, ...,  0.03841459,\n",
       "        -0.11882372, -0.07997831]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "session.run(test,feed_dict={input_data:x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputs is 50x[60*128]. We need to reshape it to [60x50x128]. Then we can calculate the softmax:\n",
    "\n",
    "softmax_w is [rnn_size, vocab_size], [128x65]\n",
    "\n",
    "[60x50x128]x[128x65]+[60x50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(3000, 128) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tf.reshape(tf.concat(outputs, 1), [-1, rnn_size])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(3000, 65) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax:0' shape=(3000, 65) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = tf.nn.softmax(logits)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01902954,  0.01288626,  0.01314334, ...,  0.01411375,\n",
       "         0.01885167,  0.01985767],\n",
       "       [ 0.01604957,  0.0141206 ,  0.01180383, ...,  0.01324264,\n",
       "         0.0210009 ,  0.01870311],\n",
       "       [ 0.01307559,  0.01469065,  0.0116342 , ...,  0.01260926,\n",
       "         0.02340574,  0.02297945],\n",
       "       ..., \n",
       "       [ 0.01656532,  0.02045839,  0.01115488, ...,  0.01176428,\n",
       "         0.02083436,  0.01658119],\n",
       "       [ 0.01537982,  0.01191368,  0.01081387, ...,  0.01424735,\n",
       "         0.01677993,  0.01711635],\n",
       "       [ 0.01438247,  0.01752337,  0.01026943, ...,  0.01559825,\n",
       "         0.02184941,  0.01647909]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "session.run(probs,feed_dict={input_data:x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits],\n",
    "                [tf.reshape(targets, [-1])],\n",
    "                [tf.ones([batch_size * seq_length])],\n",
    "                vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truediv_1:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_sum(loss) / batch_size / seq_length\n",
    "cost\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'rnnlm_1/multi_rnn_cell_49/cell_0/basic_rnn_cell/Tanh:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/multi_rnn_cell_49/cell_1/basic_rnn_cell/Tanh:0' shape=(60, 128) dtype=float32>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state = last_state\n",
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = tf.Variable(0.0, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_clip =5.\n",
    "tvars = tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'rnnlm/softmax_w:0' shape=(128, 65) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/softmax_b:0' shape=(65,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/embedding:0' shape=(65, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/weights:0' shape=(256, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/biases:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/multi_rnn_cell/cell_1/basic_rnn_cell/weights:0' shape=(256, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/multi_rnn_cell/cell_1/basic_rnn_cell/biases:0' shape=(128,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rnnlm/softmax_w:0',\n",
       " 'rnnlm/softmax_b:0',\n",
       " 'rnnlm/embedding:0',\n",
       " 'rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/weights:0',\n",
       " 'rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/biases:0',\n",
       " 'rnnlm/multi_rnn_cell/cell_1/basic_rnn_cell/weights:0',\n",
       " 'rnnlm/multi_rnn_cell/cell_1/basic_rnn_cell/biases:0',\n",
       " 'Variable:0']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "[v.name for v in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_0:0' shape=(128, 65) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_1:0' shape=(65,) dtype=float32>,\n",
       " <tensorflow.python.framework.ops.IndexedSlices at 0x7f85994bd828>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_3:0' shape=(256, 128) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_4:0' shape=(128,) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_5:0' shape=(256, 128) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_6:0' shape=(128,) dtype=float32>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip)\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.07060326e-03,  -5.24530653e-04,  -1.91177626e-03, ...,\n",
       "          9.48221641e-05,   2.58255837e-04,   3.92583752e-04],\n",
       "       [ -1.73673022e-03,  -3.51239811e-03,  -1.25999434e-03, ...,\n",
       "          1.84613760e-04,   2.57512496e-04,   1.03761151e-04],\n",
       "       [  1.92968792e-03,   5.13417297e-04,  -3.00116517e-05, ...,\n",
       "         -1.03049410e-04,  -1.06119289e-04,  -2.45183386e-04],\n",
       "       ..., \n",
       "       [ -9.14455857e-04,  -1.67382008e-03,  -3.30934674e-03, ...,\n",
       "          5.25497366e-04,   4.40616073e-04,   3.70348018e-04],\n",
       "       [ -4.17240756e-03,  -3.40628391e-03,  -1.02739211e-03, ...,\n",
       "          6.01988751e-04,   4.35684458e-04,   2.87690957e-04],\n",
       "       [  1.90374791e-03,   2.27611838e-03,   3.41343286e-04, ...,\n",
       "         -5.74903897e-05,   1.40870125e-05,  -1.27287320e-04]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(grads, feed_dict)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "train_op = optimizer.apply_gradients(zip(grads, tvars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using classes\n",
    "Now that we have learned how the networks work, we can put all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMModel():\n",
    "    def __init__(self,sample=False):\n",
    "        rnn_size = 128 # size of RNN hidden state vector\n",
    "        batch_size = 60 # minibatch size, i.e. size of dataset in each epoch\n",
    "        seq_length = 50 # RNN sequence length\n",
    "        num_layers = 2 # number of layers in the RNN\n",
    "        vocab_size = 65\n",
    "        grad_clip = 5.\n",
    "        if sample:\n",
    "            print(\"sample mode\")\n",
    "            batch_size = 1\n",
    "            seq_length = 1\n",
    "        # model.cell.state_size is (128, 128)\n",
    "        with tf.variable_scope('lstm_model_cell'):\n",
    "            reuse = tf.get_variable_scope().reuse\n",
    "            self.stacked_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicRNNCell(rnn_size, reuse=reuse) \n",
    "                                                         for _ in range(num_layers)])\n",
    "\n",
    "        self.input_data = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "        self.targets = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "        # Initial state of the LSTM memory.\n",
    "        # The memory state of the network is initialized with a vector of zeros and gets updated after reading each char. \n",
    "        self.initial_state = stacked_cell.zero_state(batch_size, tf.float32) #why batch_size\n",
    "\n",
    "        with tf.variable_scope('rnnlm_class1'):\n",
    "            softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size]) #128x65\n",
    "            softmax_b = tf.get_variable(\"softmax_b\", [vocab_size]) # 1x65\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size])  #65x128\n",
    "                inputs = tf.split(tf.nn.embedding_lookup(embedding, self.input_data), seq_length, 1)\n",
    "                inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "                #inputs = tf.split(em, seq_length, 1)\n",
    "\n",
    "        # The value of state is updated after processing each batch of chars.\n",
    "        outputs, last_state = tf.contrib.legacy_seq2seq.rnn_decoder(inputs, self.initial_state, self.stacked_cell, loop_function=None, scope='rnnlm_class1')\n",
    "        output = tf.reshape(tf.concat(outputs,1), [-1, rnn_size])\n",
    "        self.logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "        self.probs = tf.nn.softmax(self.logits)\n",
    "        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([self.logits],\n",
    "                [tf.reshape(self.targets, [-1])],\n",
    "                [tf.ones([batch_size * seq_length])],\n",
    "                vocab_size)\n",
    "        self.cost = tf.reduce_sum(loss) / batch_size / seq_length\n",
    "        self.final_state = last_state\n",
    "        self.lr = tf.Variable(0.0, trainable=False)\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars),grad_clip)\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "        \n",
    "    def sample(self, sess, chars, vocab, num=200, prime='The ', sampling_type=1):\n",
    "        state = sess.run(self.stacked_cell.zero_state(1, tf.float32))\n",
    "        for char in prime[:-1]:\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0, 0] = vocab[char]\n",
    "            feed = {self.input_data: x, self.initial_state:state}\n",
    "            [state] = sess.run([self.final_state], feed)\n",
    "\n",
    "        def weighted_pick(weights):\n",
    "            t = np.cumsum(weights)\n",
    "            s = np.sum(weights)\n",
    "            return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "        ret = prime\n",
    "        char = prime[-1]\n",
    "        for n in range(num):\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0, 0] = vocab[char]\n",
    "            feed = {self.input_data: x, self.initial_state:state}\n",
    "            [probs, state] = sess.run([self.probs, self.final_state], feed)\n",
    "            p = probs[0]\n",
    "\n",
    "            if sampling_type == 0:\n",
    "                sample = np.argmax(p)\n",
    "            elif sampling_type == 2:\n",
    "                if char == ' ':\n",
    "                    sample = weighted_pick(p)\n",
    "                else:\n",
    "                    sample = np.argmax(p)\n",
    "            else: # sampling_type == 1 default:\n",
    "                sample = weighted_pick(p)\n",
    "\n",
    "            pred = chars[sample]\n",
    "            ret += pred\n",
    "            char = pred\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "the input is always a matrix of of shape [n x m]. Where n is the batch size, m is the feature size. \n",
    "In our case, the input shape will be [60 x ??]. \n",
    "\n",
    " \n",
    "size of data is 1113000, number of batches are 371, batch size is 60 and sequence length is 50. so, 50*60*371= 1113000\n",
    "\n",
    "we have 50 epochs. \n",
    "each input matrix will represent 1 update per epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating the LSTM object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"rnn\"):\n",
    "    model = LSTMModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32),\n",
       " array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "e=1\n",
    "sess.run(tf.assign(model.lr, learning_rate * (decay_rate ** e)))\n",
    "data_loader.reset_batch_pointer()\n",
    "state = sess.run(model.initial_state)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = data_loader.next_batch()\n",
    "feed = {model.input_data: x, model.targets: y, model.initial_state:state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1709843"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\n",
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.09675249,  0.07419401,  0.10559285, ...,  0.1317708 ,\n",
       "         -0.0838413 , -0.13619834],\n",
       "        [-0.16656482,  0.2262025 ,  0.21313049, ..., -0.12080994,\n",
       "         -0.05027504,  0.03160353],\n",
       "        [-0.11570983,  0.15961714,  0.09448375, ..., -0.08197498,\n",
       "         -0.16918509,  0.06766865],\n",
       "        ..., \n",
       "        [ 0.03510161,  0.00867428, -0.1297501 , ...,  0.01044595,\n",
       "         -0.0471494 , -0.08271383],\n",
       "        [-0.25937682,  0.18290329, -0.20928687, ...,  0.10053991,\n",
       "         -0.00289368,  0.04116455],\n",
       "        [-0.10159639,  0.09477679,  0.12515672, ..., -0.00159762,\n",
       "         -0.16833328,  0.05839593]], dtype=float32),\n",
       " array([[ 0.04377746,  0.05588173,  0.33478257, ...,  0.38336733,\n",
       "         -0.12499455,  0.11230542],\n",
       "        [ 0.26025739, -0.16916114,  0.1594902 , ...,  0.09015638,\n",
       "          0.01291311,  0.18199916],\n",
       "        [-0.11651207,  0.15768678, -0.0537589 , ..., -0.136567  ,\n",
       "         -0.21685205, -0.14383744],\n",
       "        ..., \n",
       "        [ 0.34668308, -0.02540538, -0.23776405, ...,  0.13425317,\n",
       "          0.23202583,  0.2141573 ],\n",
       "        [ 0.09686469, -0.26220188,  0.27067024, ...,  0.17269139,\n",
       "          0.14760818, -0.09695639],\n",
       "        [-0.00746535,  0.21565835, -0.04120752, ..., -0.1490697 ,\n",
       "          0.00494924, -0.04040538]], dtype=float32))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train usinng LSTMModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (371 / 18550 batches, lr=0.0100)\n",
      "Train_loss=1.731   Time/Batch=38.892 ms\n",
      "\n",
      "Epoch 2 (742 / 18550 batches, lr=0.0097)\n",
      "Train_loss=1.641   Time/Batch=45.372 ms\n",
      "\n",
      "Epoch 3 (1113 / 18550 batches, lr=0.0094)\n",
      "Train_loss=1.623   Time/Batch=52.473 ms\n",
      "\n",
      "Epoch 4 (1484 / 18550 batches, lr=0.0091)\n",
      "Train_loss=1.616   Time/Batch=52.220 ms\n",
      "\n",
      "Epoch 5 (1855 / 18550 batches, lr=0.0089)\n",
      "Train_loss=1.598   Time/Batch=54.698 ms\n",
      "\n",
      "Epoch 6 (2226 / 18550 batches, lr=0.0086)\n",
      "Train_loss=1.591   Time/Batch=58.853 ms\n",
      "\n",
      "Epoch 7 (2597 / 18550 batches, lr=0.0083)\n",
      "Train_loss=1.579   Time/Batch=55.002 ms\n",
      "\n",
      "Epoch 8 (2968 / 18550 batches, lr=0.0081)\n",
      "Train_loss=1.589   Time/Batch=44.984 ms\n",
      "\n",
      "Epoch 9 (3339 / 18550 batches, lr=0.0078)\n",
      "Train_loss=1.579   Time/Batch=98.104 ms\n",
      "\n",
      "Epoch 10 (3710 / 18550 batches, lr=0.0076)\n",
      "Train_loss=1.587   Time/Batch=36.872 ms\n",
      "\n",
      "Epoch 11 (4081 / 18550 batches, lr=0.0074)\n",
      "Train_loss=1.573   Time/Batch=59.055 ms\n",
      "\n",
      "Epoch 12 (4452 / 18550 batches, lr=0.0072)\n",
      "Train_loss=1.567   Time/Batch=89.665 ms\n",
      "\n",
      "Epoch 13 (4823 / 18550 batches, lr=0.0069)\n",
      "Train_loss=1.568   Time/Batch=45.539 ms\n",
      "\n",
      "Epoch 14 (5194 / 18550 batches, lr=0.0067)\n",
      "Train_loss=1.565   Time/Batch=84.331 ms\n",
      "\n",
      "Epoch 15 (5565 / 18550 batches, lr=0.0065)\n",
      "Train_loss=1.565   Time/Batch=60.008 ms\n",
      "\n",
      "Epoch 16 (5936 / 18550 batches, lr=0.0063)\n",
      "Train_loss=1.552   Time/Batch=72.037 ms\n",
      "\n",
      "Epoch 17 (6307 / 18550 batches, lr=0.0061)\n",
      "Train_loss=1.557   Time/Batch=95.832 ms\n",
      "\n",
      "Epoch 18 (6678 / 18550 batches, lr=0.0060)\n",
      "Train_loss=1.556   Time/Batch=69.829 ms\n",
      "\n",
      "Epoch 19 (7049 / 18550 batches, lr=0.0058)\n",
      "Train_loss=1.540   Time/Batch=77.337 ms\n",
      "\n",
      "Epoch 20 (7420 / 18550 batches, lr=0.0056)\n",
      "Train_loss=1.544   Time/Batch=61.575 ms\n",
      "\n",
      "Epoch 21 (7791 / 18550 batches, lr=0.0054)\n",
      "Train_loss=1.544   Time/Batch=36.538 ms\n",
      "\n",
      "Epoch 22 (8162 / 18550 batches, lr=0.0053)\n",
      "Train_loss=1.539   Time/Batch=86.214 ms\n",
      "\n",
      "Epoch 23 (8533 / 18550 batches, lr=0.0051)\n",
      "Train_loss=1.537   Time/Batch=65.374 ms\n",
      "\n",
      "Epoch 24 (8904 / 18550 batches, lr=0.0050)\n",
      "Train_loss=1.530   Time/Batch=45.184 ms\n",
      "\n",
      "Epoch 25 (9275 / 18550 batches, lr=0.0048)\n",
      "Train_loss=1.535   Time/Batch=173.852 ms\n",
      "\n",
      "Epoch 26 (9646 / 18550 batches, lr=0.0047)\n",
      "Train_loss=1.509   Time/Batch=52.137 ms\n",
      "\n",
      "Epoch 27 (10017 / 18550 batches, lr=0.0045)\n",
      "Train_loss=1.531   Time/Batch=68.971 ms\n",
      "\n",
      "Epoch 28 (10388 / 18550 batches, lr=0.0044)\n",
      "Train_loss=1.508   Time/Batch=109.409 ms\n",
      "\n",
      "Epoch 29 (10759 / 18550 batches, lr=0.0043)\n",
      "Train_loss=1.513   Time/Batch=45.965 ms\n",
      "\n",
      "Epoch 30 (11130 / 18550 batches, lr=0.0041)\n",
      "Train_loss=1.509   Time/Batch=44.678 ms\n",
      "\n",
      "Epoch 31 (11501 / 18550 batches, lr=0.0040)\n",
      "Train_loss=1.496   Time/Batch=44.377 ms\n",
      "\n",
      "Epoch 32 (11872 / 18550 batches, lr=0.0039)\n",
      "Train_loss=1.506   Time/Batch=97.122 ms\n",
      "\n",
      "Epoch 33 (12243 / 18550 batches, lr=0.0038)\n",
      "Train_loss=1.505   Time/Batch=45.927 ms\n",
      "\n",
      "Epoch 34 (12614 / 18550 batches, lr=0.0037)\n",
      "Train_loss=1.509   Time/Batch=52.007 ms\n",
      "\n",
      "Epoch 35 (12985 / 18550 batches, lr=0.0036)\n",
      "Train_loss=1.487   Time/Batch=62.120 ms\n",
      "\n",
      "Epoch 36 (13356 / 18550 batches, lr=0.0034)\n",
      "Train_loss=1.487   Time/Batch=41.154 ms\n",
      "\n",
      "Epoch 37 (13727 / 18550 batches, lr=0.0033)\n",
      "Train_loss=1.497   Time/Batch=38.228 ms\n",
      "\n",
      "Epoch 38 (14098 / 18550 batches, lr=0.0032)\n",
      "Train_loss=1.497   Time/Batch=58.795 ms\n",
      "\n",
      "Epoch 39 (14469 / 18550 batches, lr=0.0031)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-e6fb17f4ebfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         print(\"Train_loss={:.3f}   Time/Batch={:.3f} ms\".format(\n",
      "\u001b[0;32m/home/santi/miniconda3/envs/data_science/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santi/miniconda3/envs/data_science/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santi/miniconda3/envs/data_science/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/santi/miniconda3/envs/data_science/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santi/miniconda3/envs/data_science/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_lr = 0.01\n",
    "num_epochs = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(num_epochs): # num_epochs is 5 for test, but should be higher\n",
    "        current_lr = initial_lr * (decay_rate ** e)\n",
    "        sess.run(tf.assign(model.lr, current_lr))\n",
    "        print('Epoch {} ({} / {} batches, lr={:.4f})'.format(\n",
    "            e+1,\n",
    "            (e+1) * data_loader.num_batches, \n",
    "            num_epochs * data_loader.num_batches,\n",
    "            current_lr\n",
    "        ))\n",
    "        data_loader.reset_batch_pointer()\n",
    "        state = sess.run(model.initial_state) # (2x[60x128])\n",
    "        for b in range(data_loader.num_batches): #for each batch\n",
    "            start = time.time()\n",
    "            x, y = data_loader.next_batch()\n",
    "            feed = {model.input_data: x, model.targets: y, model.initial_state:state}\n",
    "            train_loss, state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\n",
    "            end = time.time()\n",
    "        print(\"Train_loss={:.3f}   Time/Batch={:.3f} ms\".format(\n",
    "            train_loss, \n",
    "            (end - start) * 1000\n",
    "        ))\n",
    "        print()\n",
    "        #model.sample(sess, data_loader.chars , data_loader.vocab, num=200, prime='The ', sampling_type=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "with tf.variable_scope(\"sample_test\"):\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    m = LSTMModel(sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prime='The '\n",
    "num=200\n",
    "sampling_type=1\n",
    "vocab=data_loader.vocab\n",
    "chars=data_loader.chars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(m.initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print state\n",
    "sess.run(tf.global_variables_initializer())\n",
    "state=sess.run(m.initial_state)\n",
    "for char in prime[:-1]:\n",
    "    x = np.zeros((1, 1))\n",
    "    x[0, 0] = vocab[char]\n",
    "    feed = {m.input_data: x, m.initial_state:state}\n",
    "    [state] = sess.run([m.final_state], feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_pick(weights):\n",
    "    t = np.cumsum(weights)\n",
    "    s = np.sum(weights)\n",
    "    return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "ret = prime\n",
    "char = prime[-1]\n",
    "for n in range(num):\n",
    "    x = np.zeros((1, 1))\n",
    "    x[0, 0] = vocab[char]\n",
    "    feed = {m.input_data: x, m.initial_state:state}\n",
    "    [probs, state] = sess.run([m.probs, m.final_state], feed)\n",
    "    p = probs[0]\n",
    "\n",
    "    if sampling_type == 0:\n",
    "        sample = np.argmax(p)\n",
    "    elif sampling_type == 2:\n",
    "        if char == ' ':\n",
    "            sample = weighted_pick(p)\n",
    "        else:\n",
    "            sample = np.argmax(p)\n",
    "    else: # sampling_type == 1 default:\n",
    "        sample = weighted_pick(p)\n",
    "\n",
    "    pred = chars[sample]\n",
    "    ret += pred\n",
    "    char = pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample using function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The 3ESYEnEyh.3seImxt.k\\nU;Ss\\n?k?am$KGASlvrd-PoXvX:CyDNDDXOHF ?Hclt?oFG-u?rRaob'yU&KwNW3QdNHO3 WzsAISCQl?wlca$AfV&awKe\\niw&w'J'Gz!&h'uKM,uRzJpN:yv?jNUHHlqCDYnjhHScjKHs?q'mkp\\nK$YpdksOTGjztDsrs$K-W&McaY$LD!VQ\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "state=sess.run(m.initial_state)\n",
    "m.sample(sess, data_loader.chars , data_loader.vocab, num=200, prime='The ', sampling_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
